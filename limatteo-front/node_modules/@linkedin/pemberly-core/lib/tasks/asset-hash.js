const path = require('path');
const fs = require('fs-extra');
const globby = require('globby');
const BigNumber = require('bignumber.js');
const Task = require('../helpers/task');
const { getPropertyFrom } = require('../helpers/utils');
const {
  isRemoteUrl,
  isInlineData,
  duplicateSparkEntries,
  splitFileLargerThanSparkAssetSizeLimit,
  getPathsToCompress,
  relativeToAbsoluteAssetPath,
} = require('../helpers/spark');

const workerpool = require('workerpool');
const pool = workerpool.pool(
  path.resolve(__dirname, '../helpers/spark-worker.js')
);

module.exports = class Spark extends Task {
  constructor({ mpLocation, app } = {}) {
    super(...arguments);

    this.name = 'spark';
    this.app = app;
    this.mpLocation = mpLocation;
    this.hashes = {};
    this.largeFiles = [];
  }

  async run() {
    const productSpecPath = path.join(this.mpLocation, 'product-spec.json');
    const packageJsonPath = path.join(this.mpLocation, 'package.json');

    // apps will be either an empty array or [core, extended] for voyager
    let apps = getPropertyFrom('ember-addon.apps', packageJsonPath, []);
    if (this.app) {
      apps = [this.app];
    }

    const compressions = getPropertyFrom(
      'pemberly.sparkCompression',
      packageJsonPath,
      []
    );
    const mpName = getPropertyFrom('name', productSpecPath);
    const mpContext = getPropertyFrom(
      `topology.applications.${mpName}.payloads.0.context`,
      productSpecPath
    );
    this.mpContext = mpContext;
    const assetLocations = [];

    if (apps.length > 0) {
      apps.forEach(app => {
        assetLocations.push({
          name: `/${mpContext}/${app}/`,
          location: path.join(this.mpLocation, 'dist', app),
        });
      });
    } else {
      assetLocations.push({
        name: `/${mpContext}/`,
        location: path.join(this.mpLocation, 'dist'),
      });
    }

    for (const { name, location } of assetLocations) {
      this.ui.writeLine(
        `[pemberly-core] Running spark hashing on assets in '${location}'`
      );

      /*
       * First process all css (and index.html) assets as they might
       * contain "sub" assets (images, js files)
       */
      const cssAssets = await globby(
        ['index.html', '{assets,engines-dist}/**/*.css'],
        { cwd: location, absolute: true }
      );
      cssAssets.forEach(file => this.process(location, file));

      /*
       * Second, after hashing and replacing the "sub" assets then
       * hash the whole assets
       */
      const allAssets = await globby(
        ['{assets,engines-dist}/**/*.{css,html,js}'],
        { cwd: location, absolute: true }
      );
      allAssets.forEach(file => this.hash(location, file));

      /*
       * If compressions are specified in package.json then
       * compress the assets
       */
      if (compressions.length > 0) {
        const paths = getPathsToCompress(this.hashes, location);
        await this.compress(paths, location, compressions);

        // Include all of the compressed files into the hash json
        const compressedAssets = await globby(
          ['{assets,engines-dist}/**/*.{br,gz}'],
          { cwd: location, absolute: true }
        );
        compressedAssets.forEach(file => this.hash(location, file));
      }

      fs.writeJsonSync(
        path.join(location, 'sc-hashes.json'),
        { hashes: duplicateSparkEntries(name, this.hashes) },
        { spaces: 2 }
      );
      this.ui.writeLine(`  Wrote ${path.join(location, 'sc-hashes.json')}`);
      this.hashes = {};
    }

    await fs.ensureDir(path.join(this.mpLocation, 'build/pemberly-core'));
    await fs.writeJson(
      path.join(this.mpLocation, 'build/pemberly-core/spark-exclude.json'),
      this.largeFiles
    );
  }

  process(assetBaseLocation, filePath) {
    let content = fs.readFileSync(filePath, 'utf-8');
    const ext = path.extname(filePath);

    /*
     * url("/assets/icon.svg")
     * url('/assets/icon.svg')
     * url(/assets/icon.svg)
     * SCHASH["assets/favicon.ico"]
     */
    let regex = new RegExp(/url\(['|"]?(.*?)["|']?\)/, 'g');

    if (ext === '.html') {
      regex = new RegExp(/(%SCHASH\[(.*?)]%)/, 'g');

      const jsdom = require('jsdom');
      const { JSDOM } = jsdom;
      const dom = new JSDOM(content);
      const scripts = dom.window.document.querySelectorAll('script'); // eslint-disable-line @linkedin/pemberly/no-unguarded-globals

      for (let i = 0; i < scripts.length; i++) {
        const match = scripts[i].src.match(/%SCHASH\[(.*?)]%/);
        const fastbootIgnore = scripts[i].getAttribute('data-fastboot-ignore');
        const fastbootSrc = scripts[i].getAttribute('data-fastboot-src');
        if (
          match &&
          match.length === 2 &&
          (!fastbootIgnore && fastbootIgnore !== '') &&
          (!fastbootSrc && fastbootSrc !== '')
        ) {
          scripts[i].setAttribute('data-fastboot-src', match[1]);
        }
      }

      content = dom.serialize();
    }

    const replacedContent = content.replace(
      regex,
      (fullMatch, urlMatch, scHashMatch) => {
        let url = urlMatch;

        if (ext === '.html') {
          url = scHashMatch;
        }

        if (isInlineData(url) || isRemoteUrl(url)) {
          return fullMatch;
        }

        // Convert the relative assets paths such as
        // ../svg/icon.svg to an absolute path
        const fileLocation = relativeToAbsoluteAssetPath(
          assetBaseLocation,
          filePath,
          url,
          this.mpContext
        );

        if (!fs.pathExistsSync(fileLocation)) {
          this.ui.writeWarnLine(
            `Could not find  ${fileLocation}. Skipping hashing on this asset.`
          );
          return fullMatch;
        }

        const hash = this.hash(assetBaseLocation, fileLocation);

        // Do not replace index.html as the BPR will do this. This allows "local" deployment
        // to work.
        if (ext === '.html') {
          return fullMatch;
        }

        return `url(/sc/h/${hash})`;
      }
    );

    if (content !== replacedContent || ext === '.html') {
      fs.writeFileSync(filePath, replacedContent);
    }
  }

  // https://git.corp.linkedin.com:1367/plugins/gitiles/multiproducts/bpr-manifest-plugin/+/master/src/spark.ts
  hash(basePath, filePath) {
    // if we have already hashed this asset then just return the hash
    if (this.hashes[path.relative(basePath, filePath)]) {
      return this.hashes[path.relative(basePath, filePath)];
    }

    const parts = splitFileLargerThanSparkAssetSizeLimit(filePath);
    /*
     * Parts will an array of one (a single whole file) or an array of many (a single file split into
     * its parts).
     */
    const hash = parts
      .map(part => {
        const contents = fs.readFileSync(part);
        const md5Hash = require('crypto').createHash('md5');
        md5Hash.update(contents, 'utf8');
        const hashValue = new BigNumber(md5Hash.digest('hex'), 16).toString(36);
        this.hashes[path.relative(basePath, part)] = hashValue;
        return hashValue;
      })
      .join(',');

    if (parts.length > 1) {
      let pathToExclude = path.relative(
        path.resolve(basePath, '../'),
        filePath
      );

      // This is to handle the case in voyager where the relative path
      // is "up a level" because of core & extended
      if (!pathToExclude.startsWith('dist/')) {
        pathToExclude = `dist/${pathToExclude}`;
      }

      this.largeFiles.push(pathToExclude);
    }

    this.hashes[path.relative(basePath, filePath)] = hash;
    return hash;
  }

  async compress(paths, location, compressions) {
    const poolPromises = [];
    compressions.forEach(encoding => {
      this.ui.writeLine(`  Compressing ${paths.length} files with ${encoding}`);
      for (const filePath of paths) {
        poolPromises.push(
          pool.exec('compressPaths', [filePath, encoding, location])
        );
      }
    });

    await Promise.all(poolPromises).then(() => {
      if (poolPromises.length > 0) {
        pool.terminate();
      }
    });

    this.ui.writeLine(`  Finished compressing ${paths.length} assets`);
  }
};
